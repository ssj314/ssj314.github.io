---
title: 생성 모델
posted: YYYY-MM-DD hh:mm:ss +09:00
category: ["Study", "Deep Learning"]
tags: [
    "PyTorch",
    "Generative Model"
]
---

기존 딥러닝 모델은 데이터를 학습하여 정답을 찾는 것이었다. 그러나, 생성 모델은 데이터를 판별하는 것에 그치지 않는다. 입력 데이터의 분포를 파악하여 유사한 데이터를 생성해 낼 수 있다. 최근엔 엄청나게 많은 데이터를 학습하는 것이 추세이므로 생성 모델을 이용해 입력 데이터를 생성해 내기도 한다.

## 생성 모델의 구조
---
신경망처럼 분류 혹은 회귀 모델은 판별자 모델이라고 한다. 생성 모델에는 판별자뿐 아니라 기존 데이터의 특성을 추출해 새로운 조합을 만드는 생성자 모델이 있다. 

### 생성 모델의 유형
기존 데이터의 특성을 추출하는 방식에 따라 명시적 방법과 암시적 방법으로 분류한다. 명시적 방법의 대표적인 예시는 변형 오토인코더(VAE)로, 확률 변수 $p(x)$를 정의한다. 반면, 암시적 방법에 해당하는 적대적 생성 모델(GAN)은 확률 변수를 직접 정의하지 않고 오로지 신경망의 학습을 통해 컴퓨터가 알아서 정한다.
![](https://i.imgur.com/LnfddXg.png)
*Figure 1. 적대적 생성 모델과 변형 오토인코더*

## 적대적 생성 모델 (GAN)
---
생성 모델은 판별자와 생성자로 구성된다. 생성자는 새로운 데이터를 계속 생성하고 판별자는 이것과 실제 데이터를 비교하여 어느게 진짜인지 판별한다. 생성자는 판별자가 가짜 데이터를 구분하지 못 하도록 훈련하고, 판별자는 실제 데이터를 진짜로 판단하도록 훈련한다.
![](https://i.imgur.com/2tbMdf3.png)
*Figure 2. GAN의 학습 과정*

### GAN의 동작 원리
판별자의 역할을 먼저 살펴보자. 판별자는 주어진 입력 이미지 $x$에 대해 진짜일 확률 $D(x)$를 반환한다. 반면 생성자는 처음에는 노이즈 $z$를 이용해 가짜 데이터 $G(z)$를 생성해 낸다. 

### GAN의 손실함수
$D(x)$는 실제 데이터를 진짜로 판단할 확률이고, $D(G(x))$는 가짜 데이터를 진짜로 판단할 확률이다. 따라서, 판별자의 입장에서는 진짜는 진짜로, 가짜는 가짜로 판별할 수록 성능이 좋은 것이다.
$$
\max_D \; \log D(x)+\log (1-D(G(z)))
$$
반대로, 생성자는 판별자가 자신이 만든 데이터를 진짜라고 오인할 수록 성능이 좋다.
$$
\min_D \; \log (1 - D(G(z)))
$$


## GAN 구현 (w. PyTorch)
---
